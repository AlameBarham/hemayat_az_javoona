{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2872c4f",
   "metadata": {},
   "source": [
    "this soal is \"بدیهیه\"( but not in pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10be38d",
   "metadata": {},
   "source": [
    "# libraries and data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c5f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f636c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1437, 64)\n",
      "y_train.shape: (1437,)\n",
      "X_test.shape: (360, 64)\n",
      "y_test.shape: (360,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=56, stratify=y)\n",
    "\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9faa91bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[56].reshape(8, 8), cmap='gray')\n",
    "plt.show()\n",
    "print(y_train[56])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8be510",
   "metadata": {},
   "source": [
    "# appling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd16801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0519c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv f1_macro mean: 0.9759477318737677\n",
      "cv f1_macro scores: [0.97494675 0.97205254 0.98036567 0.97468343 0.97769027]\n"
     ]
    }
   ],
   "source": [
    "# Random-Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "clf = RandomForestClassifier(random_state=56)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=56), scoring=\"f1_macro\")\n",
    "print(f\"cv f1_macro mean: {scores.mean()}\")\n",
    "print(f\"cv f1_macro scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047d591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e9ec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNet\n",
    "class numberNN(nn.Module):\n",
    "    def __init__(self, input):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = numberNN(X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5424842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8325fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc461a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(epochs=10):\n",
    "    print(\"The metric is f1_score\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        all_train_preds, all_train_labels = [], []\n",
    "        all_test_preds, all_test_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                preds = torch.argmax(model(X_batch), dim=1)\n",
    "                all_train_preds.extend(preds.numpy())\n",
    "                all_train_labels.extend(y_batch.numpy())\n",
    "                \n",
    "            for X_batch, y_batch in test_loader:\n",
    "                preds = torch.argmax(model(X_batch), dim=1)\n",
    "                all_test_preds.extend(preds.numpy())\n",
    "                all_test_labels.extend(y_batch.numpy())\n",
    "        \n",
    "        f1_train = f1_score(all_train_labels, all_train_preds, average=\"macro\")\n",
    "        f1_val = f1_score(all_test_labels, all_test_preds, average=\"macro\")\n",
    "        \n",
    "        print(f\"epoch: {epoch+1},  Loss: {avg_loss:.4f},  Train: {f1_train:.4f},  Test: {f1_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43a604bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metric is f1_score\n",
      "epoch: 1,  Loss: 2.0633,  Train: 0.7243,  Test: 0.7516\n",
      "epoch: 2,  Loss: 1.5387,  Train: 0.8140,  Test: 0.8192\n",
      "epoch: 3,  Loss: 1.0736,  Train: 0.8835,  Test: 0.8790\n",
      "epoch: 4,  Loss: 0.8001,  Train: 0.9117,  Test: 0.9199\n",
      "epoch: 5,  Loss: 0.6148,  Train: 0.9282,  Test: 0.9225\n",
      "epoch: 6,  Loss: 0.5136,  Train: 0.9395,  Test: 0.9279\n",
      "epoch: 7,  Loss: 0.4491,  Train: 0.9443,  Test: 0.9389\n",
      "epoch: 8,  Loss: 0.3901,  Train: 0.9526,  Test: 0.9415\n",
      "epoch: 9,  Loss: 0.3423,  Train: 0.9574,  Test: 0.9441\n",
      "epoch: 10,  Loss: 0.3268,  Train: 0.9644,  Test: 0.9495\n",
      "epoch: 11,  Loss: 0.2924,  Train: 0.9651,  Test: 0.9468\n",
      "epoch: 12,  Loss: 0.2790,  Train: 0.9686,  Test: 0.9495\n",
      "epoch: 13,  Loss: 0.2447,  Train: 0.9749,  Test: 0.9523\n",
      "epoch: 14,  Loss: 0.2483,  Train: 0.9777,  Test: 0.9578\n",
      "epoch: 15,  Loss: 0.2330,  Train: 0.9784,  Test: 0.9551\n",
      "epoch: 16,  Loss: 0.2305,  Train: 0.9833,  Test: 0.9578\n",
      "epoch: 17,  Loss: 0.2043,  Train: 0.9847,  Test: 0.9523\n",
      "epoch: 18,  Loss: 0.2041,  Train: 0.9847,  Test: 0.9551\n",
      "epoch: 19,  Loss: 0.1783,  Train: 0.9867,  Test: 0.9579\n",
      "epoch: 20,  Loss: 0.1896,  Train: 0.9874,  Test: 0.9578\n",
      "epoch: 21,  Loss: 0.1732,  Train: 0.9895,  Test: 0.9578\n",
      "epoch: 22,  Loss: 0.1599,  Train: 0.9895,  Test: 0.9551\n",
      "epoch: 23,  Loss: 0.1337,  Train: 0.9889,  Test: 0.9551\n",
      "epoch: 24,  Loss: 0.1613,  Train: 0.9909,  Test: 0.9578\n",
      "epoch: 25,  Loss: 0.1563,  Train: 0.9909,  Test: 0.9606\n",
      "epoch: 26,  Loss: 0.1486,  Train: 0.9916,  Test: 0.9606\n",
      "epoch: 27,  Loss: 0.1280,  Train: 0.9930,  Test: 0.9605\n",
      "epoch: 28,  Loss: 0.1265,  Train: 0.9937,  Test: 0.9551\n",
      "epoch: 29,  Loss: 0.1343,  Train: 0.9937,  Test: 0.9551\n",
      "epoch: 30,  Loss: 0.1244,  Train: 0.9951,  Test: 0.9551\n"
     ]
    }
   ],
   "source": [
    "model_training(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
